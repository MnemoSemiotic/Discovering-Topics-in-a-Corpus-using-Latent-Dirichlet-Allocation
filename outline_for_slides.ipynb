{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Outline for LDA Lecture @MSU ML Club\n",
    "- Friday 11am, Oct 12\n",
    "- It is the meeting room in the offices. AES 200k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<hr><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Slide 1\n",
    "- Title: Discovering Topics in a Corpus using Latent Dirichlet Allocation\n",
    "![process high level view](images/pipeline.png)\n",
    "![logos](images/logos.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "- Hello, my name is Tovio Roberts and I'm here to talk about Latent Dirichlet Allocation, known as the other LDA, not to be confused with [Linear Discriminant Analysis](https://en.wikipedia.org/wiki/Linear_discriminant_analysis). \n",
    "\n",
    "- Before we get into LDA, \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<hr><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Slide 2: About me:\n",
    "- Tovio Roberts\n",
    "    - Former Arabic major @Wayne State, Detroit\n",
    "        - lots of language study in a variety of languages\n",
    "    - Former CompSci mentor with cognitively diverse college students\n",
    "    - Galvanize DSI 64 alumnus\n",
    "    - Lead Technical Admissions Officer for the Data Science Immersive at Galvanize\n",
    "    - Data Specialist at Carbon Collective\n",
    "    - Former CompSci major @MSU\n",
    "        - Currently IDP in Machine Learning @MSU, ~Spring 2019?\n",
    "    - Exploring Masters programs in Computational Linguistics\n",
    "    \n",
    "- github/clownfragment\n",
    "- dataisartisdata.com\n",
    "- tovioroberts@gmail.com\n",
    "- linkedin.com/in/Tovio-Roberts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "- _A little bit about me..._\n",
    "\n",
    "- _I've studied languages quite a bit, former Arabic major._\n",
    "\n",
    "- _I currently work as the lead technical admissions officer for the Data Science Immersive at Galvanize and as the data specialist (whatever that means) for a small startup called Carbon Collective working on gamifying carbon footprint reduction._\n",
    "\n",
    "- _I attended the 3 month Data Science Immersive at Galvanize last Spring._\n",
    "\n",
    "- _I worked for about 5 years as a CompSci tutor and mentor with Cognitively Diverse college students, mostly with ASD, in a one on one format, assisting with executive function, designing specialized curriculums and study plans._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<hr><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Slide 3: First, Let's Frame a Use Case\n",
    "![Consolidate Documents from different Departments](images/departments_to_corpus.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "- _So let's motivate LDA through a context._\n",
    "\n",
    "- _In a university, there are many departments. Let's say MSU, wants to digitize their study resources across all departments and create a document recommender system that will suggest materials based on documents similar to what a given student is studying. The administration plans on pooling thousands of digital documents into a single corpus._\n",
    "\n",
    "- _Notice here that the concept of a \"subject\" is defined by humans. Potentially, the documents could be given tags to facilitate searching. However, we're hoping to automate the process of document suggestion with little human-intervention._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<hr><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Slide 4: Subjects vs Topics\n",
    "- **Subject**: human-projected category, ie., History, Biology, Data Science\n",
    "- **Topic**: a latent signal discerned within a corpus, often described by a list of words/stems that \"should make sense\" to a human observer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "- _I am going to posit that, in order to deliver all appropriate study materials from many different departments, we should abandon the human-projected subject associated with the document. We might want to do this because we care primarily about the content of the document.  For example, if we're discussing formal languages, we want to make sure that content from the Linguistics department that is similar to content from the Computer Science department, such as those describing the Chomsky hierarchy of formal grammars, be related regardless._\n",
    "\n",
    "- _We want the machine to do the work of discovering the distribution of latent topics in a given document._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<hr><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Slide 5: What do We Feed to the Machine?\n",
    "![truckasaurus](images/truckasaurus.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "- _What do we feed to our machine?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<hr><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Slide 6: Term Frequency (TF) Matrix\n",
    "![bag of words image](images/bow.png)\n",
    "- aka, Bag of Words/Term Frequency\n",
    "    - order of words in the document is not relevant\n",
    "    - sparse matrix \n",
    "- Requires an NLP cleaning pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "- _Theoretically, Latent Dirichlet Allocation requires a Term Frequency Matrix, though I've used TFIDF matrices with similar results to TF matrices. Keep in mind that the input matrix is rather wide, the length of a row being the length of the vocabulary of the entire corpus. In other words, there's a column for every distinct word found in every document in the input._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<hr><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Slide 7: TF Matrix / Bag of Words\n",
    "\n",
    "| doc index | word0 | word1 | word2 | word3 |... | wordn\n",
    "|-----------|-------|-------|-------|-------|----|------\n",
    "|doc0       | 0     | 1     | 0     |  2    |... | 1\n",
    "|doc1       | 0     | 0     | 1     |  0    |... | 0 \n",
    "|doc2       | 1     | 2     | 0     |  0    |... | 0\n",
    "|doc3       | 1     | 0     | 0     |  1    |... | 1\n",
    "|...        | ...   | ...   | ...   | ...   |... | ...\n",
    "|docn       | 0     | 2     | 0     |  0    |... | 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "_So, every document in our input is represented by a row, and has a frequency value for every word in the vocabulary. \n",
    "Realistically , a given document will not contain most of the words in the vocabulary, thus this is a sparse matrix._\n",
    "\n",
    "_We arrive at a usable TF Matrix through constructing a Cleaning Pipeline. To give a sense of what this pipeline is doing, let's look at some real documents._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<hr><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Slide 8: Let's Build a Corpus\n",
    "- Sample of 36000 documents (Anki flash cards) from 3 Human-Defined Subjects\n",
    "    - 12000 from History\n",
    "    - 12000 from Data Science/Statistics\n",
    "    - 12000 from Biology\n",
    "- Using 1-grams, for sake of dimensionality, though n-grams are possible\n",
    "- Remove words most/least common across documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "_As a proof of concept, let's build a corpus where the documents come from 3 distinct, human-defined subjects, History, Data Science, and Biology. I used flash card decks contributed to ankiweb_\n",
    "\n",
    "_We can imagine that a topic-modeling algorithm searching for 3 topics will likely distinguish three topics represented by words that seem to satisfy the three subjects._\n",
    "\n",
    "_I'm using 1-grams here for \"words,\" but there's no reason that you couldn't use any n-gram representation, it just massively increases the dimensions of the sparse matrix and wasn't at all necessary given the subject delineation of this corpus._\n",
    "\n",
    "_One last adjustment that I commit is to remove the words that appear in more than a certain percentage of documents, as well as words that only appear in less than a certain number of documents. This is similar to the automatic weighting you see in Term Frequency, Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<hr><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Slide 9: Input Must be Cleaned\n",
    "![uncleaned input data](images/wordmap_data_uncleaned.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "_Here we see a wordcloud from just the Data Science cards. We can see a number of artifacts from html, javascript and LaTEX. My pipeline includes functions to strip code, numeric characters and LaTEX. I will likely rewrite my cleaning functions to keep the LaTEX in a translated form, as some cards only have LaTEX and the word 'derivative' would likely contribute to a document's topic distribution._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Slide 10: Features (words) should be Canonical\n",
    "- Stemming: reduce to a \"root\" form\n",
    "    - Eliminates tense\n",
    "- Could instead lemmatize for potentially more readable root word\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "_In general when we use a TF or TFIDF matrix, we want to stem the words. Stemming strips different forms of a given word, such as the words \"complex\" and \"complexity\", to a single canonical form._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<hr><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Slide 11: Cleaned/Stemmed Document\n",
    "![document before and after](images/doc_before_after.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "_This is a single document, before and after cleaning. The underlined words illustrate stemming, html has been removed, and everything is lowercased._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<hr><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Slide 12: Data Science Cards, Cleaned and Stemmed\n",
    "![data science wordcloud](images/data_science_wordcloud.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "_Here we see a wordcloud of the cleaned and stemmed vocabulary from the DataScience flashcard deck. The larger the word, the more frequently it occurs in the corpus._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<hr><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Slide 13: Biology Cards, Cleaned and Stemmed\n",
    "![biology wordcloud](images/biology_wordcloud.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "- _And the same for Biology_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<hr><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Slide 14: History Cards, Cleaned and Stemmed\n",
    "![history wordcloud](images/history_wordcloud.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "_And History_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<hr><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Slide 15: Cleaned Corpora Combined\n",
    "\n",
    "![Full cleaned corpus](images/full_corpus_cleaned.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "_And here we see a wordcloud for the entire corpus. We can see some remnants of markup and code, but I think we're doing ok._\n",
    "\n",
    "_I just want to take a moment and say that Data Cleaning takes a long time. In natural language processing, especially when using a bag of words or TFIDF representation of documents, cleaning is key as it provides better consistency and reduces dimensionality of your input._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<hr><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Slide 16: Some Selected Word Counts\n",
    "![some selected word counts](images/some_selected_word_counts.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "_If we look at some counts of words from the different decks, we can get an idea of word relevance or salience to a given subject. It's very telling that the word \"distribution\" occurs 800 times in the Data Science deck, and less than 40 times in each of the other two decks. The word \"cell\" does not occur in History, and \"war\" only occurs in \"History\"._\n",
    "\n",
    "_Intuitively, we can start think of modeling topics as a process involving observation of word occurrences in documents as well relative to word occurences within the corpus._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<hr><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Slide 17: What is Topic Modeling?\n",
    "- Unsupervised Learning method for finding latent semantic structures in a text or corpus\n",
    "- Common to assume that a given document is primarily \"about\" a given topic\n",
    "- Common to assume that a document clustered into a given topic will have a high occurrence of topic-salient words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "_That intuition is justified. Topic Modeling is the field within unsupervised learning dedicated to finding latent semantic structures within text and within corpora._\n",
    "\n",
    "_For our purposes, let's assume that a given document is primarily about a given topic and that that document will contain a high frequency of words representative of that topic._\n",
    "\n",
    "_Now that we have a prepared corpus and an understanding that our goal is to discern latent semantic structures in the corpus, we can more easily describe LDA._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<hr><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Slide 18: Latent Dirichlet Allocation\n",
    "- 2002: David Blei, Andrew Ng, and Michael I. Jordan\n",
    "- \"LDA yields list of salient groups of related words over a collection, with documents represented as a mixture of these groups.\"\n",
    "    - A document is a probability distribution over topics\n",
    "    - A topic is a probability distribution over words\n",
    "- More Intuitive Interpretation than SVD or NMF\n",
    "    - ie., doc0 = {topic1: 50%, topic2: 25%,  topic3 : 25%}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "_Latent Dirichlet Allocation is one of the most common topic modeling algorithms, alongside more matrix-based techniques such as Singular Value Decomposition and Non-Negative Matrix Factorization._\n",
    "\n",
    "_\"LDA is capable of yielding a list of salient groups of related words, aka 'topics', over a collection, with documents represented as a mixture of these groups or topics.\"_\n",
    "\n",
    "_We can think of a document as a probability distribution over topics, and a topic as a probability distribution over words. Notice here, again, that we will assume that documents with similar topics will use similar groups of words. **Latent topics are discovered by discovering groups of words in the corpus that frequently occur together within documents**_ \n",
    "\n",
    "_What really discern LDA from other bag of words models, like Non-negative Matrix Factorization or Singular Value Decomposition, is that we're not really focused on the term frequencies, we are concerned with the distribution of words across topics._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<hr><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Slide 18: LDA, a Simple Metaphor\n",
    "- you want to figure out peoples' (words') interests (topics) in a city based on where they hang out\n",
    "- assume that people go to specific places based on interests they share with other people who go to those places\n",
    "- assume we can associate people with interests and places with interests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "_Let's say you move to a new city and you want to figure out people's interests based on where they hang out. If you assume people go to specific places based on interests they share with other people, then we can assume that interests are represented by a cross section of people and that places draw certain people based on being intersections of interests._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<hr><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Slide 19: ... Walking around town\n",
    "\n",
    "1. Choose a number of interests/topics, k=3\n",
    "2. Guess as to what people are indicative of the given interests\n",
    "3. Guess the interests that draw a specific person to a specific place\n",
    "4. Over and over again\n",
    "    - For each place and person\n",
    "        - update likelihood of the guesses based on other people in that space\n",
    " \n",
    "- The guesses will get better \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "_You decide that there are 3 interests people may have that would lead them to a certain place._\n",
    "\n",
    "_So you take a first walk around town and record guesses as to which people represent certain interests, and you guess percentages of the 3 interests that might draw people to a given place._\n",
    "\n",
    "_Since you're new in town, you're very likely to make a lot of bad guesses. However, you're planning on repeating your walk every day for a few years, updating the guesses in your notebook on every walk._\n",
    "\n",
    "_You'll start recognizing that certain people appear in certain places, in the company of other people with similar interests. Eventually, you find that you can describe interests in terms of the people are into those interests._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<hr><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Slide 20: LDA, formal generative process \n",
    "[source](http://obphio.us/pdfs/lda_tutorial.pdf)\n",
    "- For each document:\n",
    "    - Randomly choose \n",
    "\n",
    "\n",
    "- uses a sparse Dirichlet prior:\n",
    "    - samples from a simplex so the k topics add to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<hr><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Further Study:\n",
    "- Latent Dirichlet Allocation: Towards a Deeper Understanding, Colorado Reed\n",
    "    - http://obphio.us/pdfs/lda_tutorial.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
